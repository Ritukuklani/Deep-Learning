{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NumpyToPytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uB5TvBbogLk"
      },
      "source": [
        "# Going from simple linear regression with one variable to pytorch\n",
        "<i>Referenced from the book \"Deep Learning with PyTorch Step-by-Step\" by Daniel Voigt  </i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQKrltvLom5r"
      },
      "source": [
        "## Numpy Linear Regression Blitz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LAm10_-deBC"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)    #numpy.random.seed function provides the input (i.e., the seed) to the algorithm that generates pseudo-random numbers in NumPy.\n",
        "x = np.random.rand(100, 1)\n",
        "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Y_R7Gvok4r",
        "outputId": "5e895b15-ffcc-4fb0-d421-d97c881c0a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "idx = np.arange(100)\n",
        "print(idx[:5])\n",
        "np.random.shuffle(idx)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0GCK83xozQY"
      },
      "source": [
        "train_idx = idx[:80]\n",
        "val_idx = idx[80:]\n",
        "\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_test, y_test = y[val_idx], y[val_idx]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF9mn1uko1lU",
        "outputId": "644dc06a-d614-48a6-c8a8-1c036044f7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(x_train, y_train,'o')\n",
        "plt.plot(x_test, y_test,'x')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6caaf75eb8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P6C96Uzo5Vi"
      },
      "source": [
        "## Two main init steps for training a model\n",
        "<ol> \n",
        "        <li> Random initialize parameters or weights </li>\n",
        "        <li> Init hyperparameters (epochs, learning rate)\n",
        "    </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCitBx3Bo23V",
        "outputId": "1508b70d-a0e7-4f46-806c-0c0a54fbdf35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Initializes parameters \"a\" and \"b\" randomly\n",
        "np.random.seed(42)\n",
        "a = np.random.randn(1)\n",
        "b = np.random.randn(1)\n",
        "\n",
        "\n",
        "print(a, b)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.49671415] [-0.1382643]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcZ5o3A_o7Zs"
      },
      "source": [
        "# Sets learning rate\n",
        "lr = 1e-1\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaiu58Puo85O",
        "outputId": "9026c4b4-08c4-4cda-ab5a-e9679a19b9a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train\n",
        "    error = y_train - yhat\n",
        "    loss =(error ** 2).mean()\n",
        "    \n",
        "    # Computes gradients for both \"a\" and \"b\" parameters\n",
        "    a_grad = -2 * error.mean()\n",
        "    b_grad = -2 * (x_train * error).mean()\n",
        "    \n",
        "    # Updates parameters using gradients and the learning rate\n",
        "    a = a - lr * a_grad\n",
        "    b = b - lr * b_grad\n",
        "    \n",
        "print(a, b)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.02354094] [1.96896411]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i1272bdpAMr"
      },
      "source": [
        "### Confirm that the results are correct using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6pAAsjao-Xs",
        "outputId": "0530fcc1-a5ef-4455-982e-c5a7b7b0129e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linr = LinearRegression()\n",
        "linr.fit(x_train, y_train)\n",
        "print(linr.intercept_, linr.coef_[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.02354075] [1.96896447]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cMUbUtopVKm"
      },
      "source": [
        "# Torch it up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOHecMWoMZmv",
        "outputId": "24acb754-daea-4429-a496-4ce3a65ad6d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZA3f6ofpCOf"
      },
      "source": [
        "import torch \n",
        "import torch.optim as optim   #to update weights when dealing with tensors\n",
        "import torch.nn as nn         #for creating PyTorch models\n",
        "from torchviz import make_dot #vizualize the computation graph"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIj_XwcppYpy",
        "outputId": "e5364f55-e223-45a8-d257-3f78b200277b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
        "# and then we send them to the chosen device\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
        "\n",
        "# Here we can see the difference - notice that .type() is more useful\n",
        "# since it also tells us WHERE the tensor is (device)\n",
        "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEdnhplapgoX",
        "outputId": "2b0e4fbc-75a4-4e62-99f1-aecd649747ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zt92y9yplr3",
        "outputId": "0e6b4a1a-4118-45a4-df8b-a938f477ff6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    # No more manual computation of gradients! \n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We just tell PyTorch to work its way BACKWARDS from the specified loss!\n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "#     print('a',a.grad)\n",
        "#     print('b',b.grad)\n",
        "    \n",
        "    # We need to use NO_GRAD to keep the update out of the gradient computation\n",
        "    # Why is that? It boils down to the DYNAMIC GRAPH that PyTorch uses...\n",
        "    with torch.no_grad():\n",
        "        a -= lr * a.grad\n",
        "        b -= lr * b.grad\n",
        "    \n",
        "    # PyTorch is \"clingy\" to its computed gradients, we need to tell it to let it go...\n",
        "    a.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "print(a,b)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQngy2_Yp29E",
        "outputId": "dc2aa868-cdd8-47b7-a3d7-9ca1923a51f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "from torchviz import make_dot\n",
        "make_dot(yhat)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f6cab7c24a8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"171pt\"\n viewBox=\"0.00 0.00 171.50 171.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 167)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-167 167.5,-167 167.5,4 -4,4\"/>\n<!-- 140104710234968 -->\n<g id=\"node1\" class=\"node\">\n<title>140104710234968</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"118,-21 26,-21 26,0 118,0 118,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 140104710235136 -->\n<g id=\"node2\" class=\"node\">\n<title>140104710235136</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-92 0,-92 0,-57 54,-57 54,-92\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140104710235136&#45;&gt;140104710234968 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140104710235136&#45;&gt;140104710234968</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-56.6724C45.4798,-48.2176 52.5878,-38.1085 58.6352,-29.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-31.4169 64.4601,-21.2234 55.8452,-27.3906 61.5714,-31.4169\"/>\n</g>\n<!-- 140104694570624 -->\n<g id=\"node3\" class=\"node\">\n<title>140104694570624</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-85 72.5,-85 72.5,-64 163.5,-64 163.5,-85\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-71.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140104694570624&#45;&gt;140104710234968 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140104694570624&#45;&gt;140104710234968</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-63.9317C103.7191,-54.6309 93.821,-40.8597 85.7479,-29.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-27.3753 79.761,-21.2979 82.7553,-31.4608 88.4395,-27.3753\"/>\n</g>\n<!-- 140104694568888 -->\n<g id=\"node4\" class=\"node\">\n<title>140104694568888</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-163 91,-163 91,-128 145,-128 145,-163\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-135.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140104694568888&#45;&gt;140104694570624 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140104694568888&#45;&gt;140104694570624</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-127.9494C118,-118.058 118,-105.6435 118,-95.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-95.0288 118,-85.0288 114.5001,-95.0289 121.5001,-95.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NON707Gp9MH",
        "outputId": "54babae3-5d53-43f2-a661-537df7b5eee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters\n",
        "# with torch.no_grad():\n",
        "#     a -= lr * a.grad\n",
        "#     b -= lr * b.grad\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    \n",
        "    # DEFINE LOSS FUNCTION\n",
        "    #error = y_train_tensor - yhat\n",
        "    #loss = (error ** 2).mean()\n",
        "    loss_fn = nn.MSELoss(reduction='mean')\n",
        "    loss = loss_fn(y_train_tensor, yhat)\n",
        "\n",
        "    loss.backward()    \n",
        "    \n",
        "    \n",
        "    # No more manual update!\n",
        "    # with torch.no_grad():\n",
        "    #     a -= lr * a.grad\n",
        "    #     b -= lr * b.grad\n",
        "    optimizer.step()\n",
        "    \n",
        "    # No more telling PyTorch to let gradients go!\n",
        "    # a.grad.zero_()\n",
        "    # b.grad.zero_()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(a, b)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVskolHZqG4i"
      },
      "source": [
        "Observe that the weights are same as what we got before when we performed linear regression with numpy. Sanity check to confirm that we have used pytorch corrrectly."
      ]
    }
  ]
}