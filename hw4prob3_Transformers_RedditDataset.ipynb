{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4prob3-Transformers-RedditDataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2469528bbd541c58807d1222768d388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_77882cf1086e409aa43222f7b355e3e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6667128a78b4b898c822de75166714d",
              "IPY_MODEL_36a7a10cbe004744a3d0b5e4af3f4167"
            ]
          }
        },
        "77882cf1086e409aa43222f7b355e3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6667128a78b4b898c822de75166714d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6dad273625ff4091b0664a3fc19a5411",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32a2d8f2278d47a894614c93fca2564a"
          }
        },
        "36a7a10cbe004744a3d0b5e4af3f4167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a48635ad8c44e7b83aa88c697132fa0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:16&lt;00:00, 25.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a75e488b4574fb594c427ea4f6d9aaa"
          }
        },
        "6dad273625ff4091b0664a3fc19a5411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32a2d8f2278d47a894614c93fca2564a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a48635ad8c44e7b83aa88c697132fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a75e488b4574fb594c427ea4f6d9aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37f313e624b84e9e94f8305cd8d8884d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5075cd2f1d14d5cb893ec9c27903404",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_59eee07c736d4322b01014422b0d8467",
              "IPY_MODEL_c93c865638ec46e2803c6c9f94faa427"
            ]
          }
        },
        "e5075cd2f1d14d5cb893ec9c27903404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59eee07c736d4322b01014422b0d8467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08a261125fbc48d6b945ec306d1d09d0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d53b9c67e694bae9265430098a191a4"
          }
        },
        "c93c865638ec46e2803c6c9f94faa427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a1fa22340f14d67b5c1cc18d8a8f668",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:16&lt;00:00, 25.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f15685140994240a7c7a14ed1945ad5"
          }
        },
        "08a261125fbc48d6b945ec306d1d09d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d53b9c67e694bae9265430098a191a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a1fa22340f14d67b5c1cc18d8a8f668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f15685140994240a7c7a14ed1945ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ritukuklani/Deep-Learning/blob/main/hw4prob3_Transformers_RedditDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "In this problem we will use the BERT model for sentiment analysis. We will start with a pre-trained BERT model and fine-tune it on a dataset of Google Play store reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjsbi1u3QFEM",
        "outputId": "52fe2749-eaec-4c64-95a1-c5484985cbf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.3MB 4.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 28.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 56.5MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqoaFpVpoM8",
        "outputId": "1df83209-03a0-45a7-c4e6-a42a8752e57b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "numpy 1.18.5\n",
            "pandas 1.1.3\n",
            "torch 1.6.0+cu101\n",
            "transformers 3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Download the Google Play app reviews dataset using the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgPRhuMzi9ot",
        "outputId": "e25bc599-f788-4e4f-e27f-424ad0c07046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 49.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "7.17MB [00:00, 112MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7GO8vXo6IVO"
      },
      "source": [
        "Here is how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS9GWErSidrA"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLyKc7I6Qp",
        "outputId": "beda7030-2cf5-4f9e-a80d-12c091c81257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars Panzerbjørn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AiAdQ3j6SDe"
      },
      "source": [
        "Let's first check the size of the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2jE6am7Dpo",
        "outputId": "95dd885c-d5d1-4110-e8a0-a4db41d0adc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q1. How many samples are there in this dataset? \n",
        "df.shape\n",
        "\n",
        "# The number of samples in the dataset are 15746"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15746, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwh_rW4Efhs3",
        "outputId": "04c7308e-8a02-4f51-def2-057e71ebeca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "# TODO: Q2. Plot a histogram of review scores. These can be accessed in the df.score field in the above dataframe. Which score is the most common?\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.countplot(df.score)\n",
        "plt.xlabel('review score');\n",
        "\n",
        "#The most common review score is 3."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZM0GKviobjM"
      },
      "source": [
        "If correctly plotted, you should be able to see that this is a somewhat imbalanced dataset. Let's first convert the dataset into three classes: negative, neutral, and positive sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tY3ECJDPaz",
        "outputId": "c0b526a0-fbfb-4423-f456-cdd868724a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "# TODO: Q3. Plot the histogram of review sentiments, and show that it is now approximately balanced.\n",
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names);\n",
        "\n",
        "#The graph shows that the scores are balanced."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWD0lEQVR4nO3df7SdVX3n8feHBH+iAhIpJtBQTXXQKkqKUGvHyhpE64jLIqIiUZlJnUGn2rEtzppVFKWDY2cY8VelEg3WFhFLoYwVMwhqHVGCIhAQyaAMZKGkJKCO1TbwnT+efcsx5N59E3Luzc19v9Y66+5nP7/2zZN7Pmc/P/ZJVSFJ0lT2mO0GSJJ2fYaFJKnLsJAkdRkWkqQuw0KS1LVwthswDvvtt18tXbp0tpshSXPKNddc8/dVtWhb83bLsFi6dClr166d7WZI0pyS5LbJ5nkaSpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1LVbPsEtaW547vufO9tN2O195c1f2SnbsWchSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1jTUsknwvyfVJrk2yttXtm2RNklvaz31afZKcnWR9kuuSPHtkOyva8rckWTHONkuSHmwmeha/WVWHVtXyNn0qcHlVLQMub9MALwKWtddK4MMwhAtwGvAc4HDgtImAkSTNjIWzsM9jgee38mrgSuAPW/15VVXAVUn2TnJAW3ZNVW0CSLIGOAb4y53RmMN+/7ydsRl1XPPek8ay3f97+q+MZbt6wEF/dP1sN0G7gHH3LAr4fJJrkqxsdftX1Z2t/H1g/1ZeDNw+su4drW6y+p+TZGWStUnWbty4cWf+DpI07427Z/HrVbUhyROANUm+PTqzqipJ7YwdVdU5wDkAy5cv3ynblCQNxtqzqKoN7eddwEUM1xx+0E4v0X7e1RbfABw4svqSVjdZvSRphowtLJI8OsljJsrA0cANwCXAxB1NK4CLW/kS4KR2V9QRwL3tdNVlwNFJ9mkXto9udZKkGTLO01D7AxclmdjPX1TV55JcDVyQ5GTgNuD4tvxngRcD64GfAK8HqKpNSd4FXN2WO33iYrckaWaMLSyq6lbgmduovxs4ahv1BZwyybZWAat2dhslSdPjE9ySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lS19jDIsmCJN9McmmbPjjJ15KsT/KpJA9r9Q9v0+vb/KUj23h7q785yQvH3WZJ0s+biZ7F7wI3jUy/Bzirqp4MbAZObvUnA5tb/VltOZIcApwAPA04BvhQkgUz0G5JUjPWsEiyBPgt4KNtOsALgAvbIquBl7XysW2aNv+otvyxwPlV9bOq+i6wHjh8nO2WJP28cfcs/gfwB8D9bfrxwD1VtaVN3wEsbuXFwO0Abf69bfl/rt/GOv8sycoka5Os3bhx487+PSRpXhtbWCR5CXBXVV0zrn2Mqqpzqmp5VS1ftGjRTOxSkuaNhWPc9nOBlyZ5MfAI4LHA+4C9kyxsvYclwIa2/AbgQOCOJAuBxwF3j9RPGF1HkjQDxtazqKq3V9WSqlrKcIH6C1X1GuAK4Li22Arg4la+pE3T5n+hqqrVn9DuljoYWAZ8fVztliQ92Dh7FpP5Q+D8JO8Gvgmc2+rPBT6RZD2wiSFgqKp1SS4AbgS2AKdU1X0z32xJmr9mJCyq6krgyla+lW3czVRVPwVeMcn6ZwBnjK+FkqSp+AS3JKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNa2wSHL5dOokSbunhVPNTPII4FHAfkn2AdJmPRZYPOa2SZJ2EVOGBfA7wFuAJwLX8EBY/BD4wBjbJUnahUwZFlX1PuB9Sd5cVe+foTZJknYxvZ4FAFX1/iS/BiwdXaeqzhtTuyRJu5BphUWSTwBPAq4F7mvVBRgWkjQPTCssgOXAIVVV42yMJGnXNN3nLG4AfmF7NpzkEUm+nuRbSdYleWerPzjJ15KsT/KpJA9r9Q9v0+vb/KUj23p7q785yQu3px2SpIduumGxH3BjksuSXDLx6qzzM+AFVfVM4FDgmCRHAO8BzqqqJwObgZPb8icDm1v9WW05khwCnAA8DTgG+FCSBdP/FSVJD9V0T0O9Y3s33E5Z/bhN7tleBbwAeHWrX922/WHg2JH9XAh8IEla/flV9TPgu0nWA4cDX93eNkmSdsx074b64o5svPUArgGeDHwQ+D/APVW1pS1yBw883LcYuL3tb0uSe4HHt/qrRjY7us7ovlYCKwEOOuigHWmuJGkS0x3u40dJftheP01yX5If9tarqvuq6lBgCUNv4KkPsb1T7eucqlpeVcsXLVo0rt1I0rw03Z7FYybKI6eGjpjuTqrqniRXAEcCeydZ2HoXS4ANbbENwIHAHUkWAo8D7h6pnzC6jiRpBmz3qLM1+GtgyruSkixKsncrPxL4V8BNwBXAcW2xFcDFrXxJm6bN/0K77nEJcEK7W+pgYBnw9e1ttyRpx033obyXj0zuwfDcxU87qx0ArG7XLfYALqiqS5PcCJyf5N3AN4Fz2/LnAp9oF7A3MdwBRVWtS3IBcCOwBTilqu5DkjRjpns31L8eKW8BvsdwKmpSVXUd8Kxt1N/KcP1i6/qfAq+YZFtnAGdMs62SpJ1sutcsXj/uhkiSdl3TvRtqSZKLktzVXp9JsmTcjZMk7Rqme4H7YwwXmp/YXn/T6iRJ88B0w2JRVX2sqra018cBH2aQpHliumFxd5ITkyxorxMZnoGQJM0D0w2LNwDHA98H7mR4DuJ1Y2qTJGkXM91bZ08HVlTVZoAk+wJ/whAikqTd3HR7Fs+YCAqAqtrENp6hkCTtnqYbFnsk2WdiovUsptsrkSTNcdN9w/9vwFeTfLpNvwKfqJakeWO6T3Cfl2QtwxcXAby8qm4cX7MkSbuSaZ9KauFgQEjSPLTdQ5RLkuYfw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1jS0skhyY5IokNyZZl+R3W/2+SdYkuaX93KfVJ8nZSdYnuS7Js0e2taItf0uSFeNqsyRp28bZs9gC/MeqOgQ4AjglySHAqcDlVbUMuLxNA7wIWNZeK4EPwxAuwGnAc4DDgdMmAkaSNDPGFhZVdWdVfaOVfwTcBCwGjgVWt8VWAy9r5WOB82pwFbB3kgOAFwJrqmpTVW0G1gDHjKvdkqQHm5FrFkmWAs8CvgbsX1V3tlnfB/Zv5cXA7SOr3dHqJqvfeh8rk6xNsnbjxo07tf2SNN+NPSyS7AV8BnhLVf1wdF5VFVA7Yz9VdU5VLa+q5YsWLdoZm5QkNWMNiyR7MgTFJ6vqr1r1D9rpJdrPu1r9BuDAkdWXtLrJ6iVJM2Scd0MFOBe4qar++8isS4CJO5pWABeP1J/U7oo6Ari3na66DDg6yT7twvbRrU6SNEMWjnHbzwVeC1yf5NpW95+AM4ELkpwM3AYc3+Z9FngxsB74CfB6gKralORdwNVtudOratMY2y1J2srYwqKq/g7IJLOP2sbyBZwyybZWAat2XuskSdvDJ7glSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHWNLSySrEpyV5IbRur2TbImyS3t5z6tPknOTrI+yXVJnj2yzoq2/C1JVoyrvZKkyY2zZ/Fx4Jit6k4FLq+qZcDlbRrgRcCy9loJfBiGcAFOA54DHA6cNhEwkqSZM7awqKovAZu2qj4WWN3Kq4GXjdSfV4OrgL2THAC8EFhTVZuqajOwhgcHkCRpzGb6msX+VXVnK38f2L+VFwO3jyx3R6ubrP5BkqxMsjbJ2o0bN+7cVkvSPDdrF7irqoDaids7p6qWV9XyRYsW7azNSpKY+bD4QTu9RPt5V6vfABw4stySVjdZvSRpBs10WFwCTNzRtAK4eKT+pHZX1BHAve101WXA0Un2aRe2j251kqQZtHBcG07yl8Dzgf2S3MFwV9OZwAVJTgZuA45vi38WeDGwHvgJ8HqAqtqU5F3A1W2506tq64vmkqQxG1tYVNWrJpl11DaWLeCUSbazCli1E5smSdpOPsEtSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdc2ZsEhyTJKbk6xPcupst0eS5pM5ERZJFgAfBF4EHAK8Kskhs9sqSZo/5kRYAIcD66vq1qr6R+B84NhZbpMkzRupqtluQ1eS44BjqurftOnXAs+pqjeNLLMSWNkmnwLcPOMNnTn7AX8/243QDvP4zV27+7H7xapatK0ZC2e6JeNSVecA58x2O2ZCkrVVtXy226Ed4/Gbu+bzsZsrp6E2AAeOTC9pdZKkGTBXwuJqYFmSg5M8DDgBuGSW2yRJ88acOA1VVVuSvAm4DFgArKqqdbPcrNk0L0637cY8fnPXvD12c+ICtyRpds2V01CSpFlkWEiSugyLOS7J3kn+/cj0E5NcOJttUl+SpUlevYPr/nhnt0d9Sd6Y5KRWfl2SJ47M++juPqqE1yzmuCRLgUur6umz3BRthyTPB95WVS/ZxryFVbVlinV/XFV7jbN9mlqSKxmO39rZbstMsWcxZu0T5E1J/izJuiSfT/LIJE9K8rkk1yT5cpKntuWflOSqJNcneffEp8gkeyW5PMk32ryJ4U7OBJ6U5Nok7237u6Gtc1WSp4205coky5M8OsmqJF9P8s2RbaljB47nx9sIBBPrT/QKzgSe147bW9sn1UuSfAG4fIrjrR3Qjtu3k3yyHb8LkzwqyVHtb+D69jfx8Lb8mUluTHJdkj9pde9I8rZ2PJcDn2zH75Ejf1tvTPLekf2+LskHWvnE9jd3bZKPtDHv5o6q8jXGF7AU2AIc2qYvAE4ELgeWtbrnAF9o5UuBV7XyG4Eft/JC4LGtvB+wHkjb/g1b7e+GVn4r8M5WPgC4uZX/GDixlfcGvgM8erb/rebCaweO58eB40bWnziez2foEU7Uvw64A9h3quM9ug1f233cCnhum14F/GfgduCXW915wFuAxzMMFzTx7713+/kOht4EwJXA8pHtX8kQIIsYxrGbqP9b4NeBfwH8DbBnq/8QcNJs/7tsz8uexcz4blVd28rXMPzH/TXg00muBT7C8GYOcCTw6Vb+i5FtBPjjJNcB/wtYDOzf2e8FwMSn2uOBiWsZRwOntn1fCTwCOGi7f6v5a3uO5/ZYU1WbWnlHjremdntVfaWV/xw4iuFYfqfVrQZ+A7gX+ClwbpKXAz+Z7g6qaiNwa5IjkjweeCrwlbavw4Cr2/+Ro4Bf2gm/04yZEw/l7QZ+NlK+j+GP/p6qOnQ7tvEahk8th1XVPyX5HsOb/KSqakOSu5M8A3glQ08Fhjei366q3XmwxXHanuO5hXa6N8kewMOm2O7/Gylv9/FW19YXaO9h6EX8/ELDQ8CHM7yhHwe8CXjBduznfIYPZ98GLqqqShJgdVW9fYdavguwZzE7fgh8N8krADJ4Zpt3FfDbrXzCyDqPA+5qbxy/Cfxiq/8R8Jgp9vUp4A+Ax1XVda3uMuDN7T8wSZ71UH+heW6q4/k9hk+UAC8F9mzl3nGb7Hhrxx2U5MhWfjWwFlia5Mmt7rXAF5PsxfD38lmGU7nPfPCmpjx+FzF8hcKrGIIDhtOUxyV5AkCSfZPMqWNqWMye1wAnJ/kWsI4Hvp/jLcDvtdMPT2boEgN8Elie5HrgJIZPLVTV3cBXktwwemFtxIUMoXPBSN27GN60rkuyrk3roZnseP4Z8C9b/ZE80Hu4DrgvybeSvHUb29vm8dZDcjNwSpKbgH2As4DXM5w+vB64H/hThhC4tP0N/h3we9vY1seBP524wD06o6o2AzcxDPf99VZ3I8M1ks+37a5hx05Vzhpvnd3FJHkU8A+t63oCw8Vu74SRHoJ4i/lD5jWLXc9hwAfaKaJ7gDfMcnskyZ6FJKnPaxaSpC7DQpLUZVhIkroMC8172UVH6s1WI9O2sYfOHvM+D03y4nHuQ3OTF7i1W2l3kaWq7p/ttjxUmWJk2jHu83UMYx69aab2qbnBnoXmvPYJ/OYk5wE3AAcm+f0kV7dRQ9/ZljszySkj602MIjo6Uu+CDKP3Tqz7O63+g0le2soXJVnVym9IcsZW7VmQYbTZG9popm9t9VONTHt2kv+d5NY8MErt1iPTPj/JpSNtX922c1uSlyf5r21/n0uyZ1vusCRfbPu8LMkBrf7KJO/JMArqd5I8L8nDgNOBV7Z9vnIcx0tzk2Gh3cUy4ENV9TTgKW36cOBQ4LAkv8Ew9MnxI+sc3+pGnQzcW1W/Cvwq8G+THAx8GXheW2YxMPFFN88DvrTVNg4FFlfV06vqV4CPtfpzgDdX1WHA2xhGHp1wAMPopC9hCAmAU4EvV9WhVXXWNn7nJzGMWfRShoHxrmj7+wfgt1pgvJ9h1NvDGEZaHQ22hVV1OMOoAadV1T8CfwR8qu1z638bzWM+lKfdxW1VdVUrH91e32zTezEMH35ukidk+IazRcDmqrq9Pd3LyLrPGPl0/ziG4Pky8JYM34Z2I7BP+5R+JPAftmrLrcAvJXk/8D8ZhnjYiwdGpp1Y7uEj6/x1O3V2Y5Lpji77t23sqOuBBcDnWv31DCPhPgV4OrCm7XMBcOfI+n/Vfk6MnCtNyrDQ7mJ0xNYA/6WqPrKN5T7NMJLoL/DgXsXEum+uqsseNCPZGziGoSexL0PP5MdV9aPR5apqcxtI8IUMI/0ez/DpfaqRhkdHss0ky2xznaq6P8k/1QMXIO9n+NsOsK6qjpxqfYaRc30v0JQ8DaXd0WXAG9qneZIsnhjtkyEgTmAIjE9Psu6/Gznn/8tJHt3mXcXwpv8lhp7G29rPn5NkP2CPqvoMw+Bxz66qqUamnUxvZNqem4FFaSOtJtkzI9+cOKZ9ajdlWGi3U1WfZ/jiqK+2UzQX0t4Aq2pdK2+oqju3sfpHGU4zfaNd9P4ID3zq/jLDef71wDcYehcPCguGaxpXZviSmz8HJr7DYLKRaSfTG5l2Su0axHHAe9o+r2U4FTaVK4BDvMCtrXnrrCSpy56FJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnq+v/aiqBqw2HPiwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Let's now load a pre-trained BERT model and the corresponding tokenizer, which converts text data into tokens. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuIfa6Usj4l0",
        "outputId": "0eb089c3-2a72-40e7-b677-fe2709499e98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 30.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hFWMWRNmSB5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZQi6dg1jnkA"
      },
      "source": [
        "from transformers import BertTokenizer  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AfJSZ8NNLF"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "Let's see how tokenization works. Here is the test sentence. Convert into tokens using the `tokenizer.tokenize` and `tokenizer.convert_tokens_to_ids` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "source": [
        "sample_txt = 'Every day feels like the same during the lock down.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFhpHpsoWO7",
        "outputId": "ac1ad1c0-f651-4259-d6dc-758bb0e1054a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q4. Print the tokens and token ids of the sample text above.\n",
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sentence: Every day feels like the same during the lock down.\n",
            "   Tokens: ['Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.']\n",
            "Token IDs: [4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "BERT has special tokens for sentence separators \\[SEP\\] and unknown words \\[UNK\\]. This can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method, which takes the test sentence and encodes it into `input_ids`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "outputId": "4e03bdf2-494b-413d-9a6b-30e6c1638427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBmcOla0yQR",
        "outputId": "5e09cab0-62f0-46fd-da48-3d694c22f00c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205,  119,\n",
              "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiv5LLiw03Ox",
        "outputId": "771a10ca-9732-48c6-d032-9611bc961e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "Use the `tokenizer.convert_ids_to_tokens` method to invert the encoded token ids (the above tensor of length 32) and visualize the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagGoafKLUwW",
        "outputId": "925a08f1-9661-491a-b37c-28dde443e64d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q5. Invert the encoded token ids.\n",
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Every',\n",
              " 'day',\n",
              " 'feels',\n",
              " 'like',\n",
              " 'the',\n",
              " 'same',\n",
              " 'during',\n",
              " 'the',\n",
              " 'lock',\n",
              " 'down',\n",
              " '.',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most reviews in the dataset contain less than around 120 tokens, but let us choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "source": [
        "MAX_LEN = 160"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "# Building the dataset\n",
        "\n",
        "Let's now create a dataset using the tokenizer. Here is some code that does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTKQLi2Llifq"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data into 90-5-5 train-validation-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vWzoo81dvO",
        "outputId": "af7d2025-398d-433c-8e1c-5ddd96fbd091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q6. Create three data frames: df_train, df_val, df_train as above and print their shapes.\n",
        "df_train, df_test = train_test_split(df, test_size = 0.1)\n",
        "df_val, df_test = train_test_split(df_test, test_size = 0.5)\n",
        "print('Shape of Training DataFrame : {}'.format(df_train.shape))\n",
        "print('Shape of Validation DataFrame : {}'.format(df_val.shape))\n",
        "print('Shape of Testing DataFrame : {}'.format(df_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Training DataFrame : (14171, 12)\n",
            "Shape of Validation DataFrame : (787, 12)\n",
            "Shape of Testing DataFrame : (788, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODDxMKsPHqI"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJZOPLydl9ub"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93ldSN47FeT",
        "outputId": "bcb55d96-6bee-40ca-98b4-de04c486116a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "Let's now load the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Load the model using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P41FayISNRI",
        "outputId": "60b4b22a-289a-41fb-faa3-a03e4131631d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "a2469528bbd541c58807d1222768d388",
            "77882cf1086e409aa43222f7b355e3e6",
            "e6667128a78b4b898c822de75166714d",
            "36a7a10cbe004744a3d0b5e4af3f4167",
            "6dad273625ff4091b0664a3fc19a5411",
            "32a2d8f2278d47a894614c93fca2564a",
            "7a48635ad8c44e7b83aa88c697132fa0",
            "6a75e488b4574fb594c427ea4f6d9aaa",
            "37f313e624b84e9e94f8305cd8d8884d",
            "e5075cd2f1d14d5cb893ec9c27903404",
            "59eee07c736d4322b01014422b0d8467",
            "c93c865638ec46e2803c6c9f94faa427",
            "08a261125fbc48d6b945ec306d1d09d0",
            "5d53b9c67e694bae9265430098a191a4",
            "1a1fa22340f14d67b5c1cc18d8a8f668",
            "9f15685140994240a7c7a14ed1945ad5"
          ]
        }
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2469528bbd541c58807d1222768d388",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37f313e624b84e9e94f8305cd8d8884d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And encode our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1aoFxbQSn15"
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is the sequence of hidden states of the last layer of the model. The `pooled_output` can be thought of as a summary of the content in the test sentence. Try printing out the sizes of `last_hidden_state` and `pooled_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJHXNpIbcci",
        "outputId": "de1b74ff-1d92-467e-a8dc-b33faf8d13a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q7. Print the sizes of the hidden states and the pooled output.\n",
        "last_hidden_state_size = last_hidden_state.shape\n",
        "pooled_output_size = pooled_output.shape\n",
        "print('Size of last_hidden_state : {}'.format(last_hidden_state_size))\n",
        "print('Size of pooled_output : {}'.format(pooled_output_size))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of last_hidden_state : torch.Size([1, 32, 768])\n",
            "Size of pooled_output : torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Note that our sentiment classifier takes the BERT backbone and adds a dropout layer (for regularization) and a linear dense layer, which we train using cross-entropy. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0yQnuSFsjDp"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7p__CqdaMO"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTCj46Zamry",
        "outputId": "97c83be4-2575-499d-8df9-28f7479b4036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3082, 0.2829, 0.4089],\n",
              "        [0.4332, 0.2614, 0.3055],\n",
              "        [0.3085, 0.2158, 0.4757],\n",
              "        [0.2675, 0.3188, 0.4137],\n",
              "        [0.2868, 0.2168, 0.4964],\n",
              "        [0.4362, 0.1725, 0.3913],\n",
              "        [0.3782, 0.2553, 0.3665],\n",
              "        [0.4796, 0.2790, 0.2413],\n",
              "        [0.2153, 0.2238, 0.5608],\n",
              "        [0.2729, 0.4071, 0.3200],\n",
              "        [0.2074, 0.2851, 0.5075],\n",
              "        [0.3538, 0.3384, 0.3078],\n",
              "        [0.2557, 0.3258, 0.4185],\n",
              "        [0.2635, 0.3345, 0.4020],\n",
              "        [0.3004, 0.2471, 0.4524],\n",
              "        [0.3792, 0.2573, 0.3635]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To train the model, we will use the AdamW optimizer and a linear learning-rate scheduler with no warmup steps, along with the cross-entropy loss. Five epochs (full passes through the training data should be enough) should be enough, but you can experiment with more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-ArJ2fCCcU"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzl9UhuNx1_Q"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    # TODO Q8. Complete the incomplete code snippets below to finish training.\n",
        "    \n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "    # input_ids = \n",
        "    # attention_mask = \n",
        "    # targets = \n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # correct_predictions += \n",
        "    # losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Let's write another function that helps us evaluate the model on a given data loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeRorVGIKre"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  # TODO: Q9. Reproduce the above code but only evaluate the model (without any weight updates).\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for d in data_loader:\n",
        "      input_ids = d['input_ids'].to(device)\n",
        "      attention_mask = d['attention_mask'].to(device)\n",
        "      targets = d['targets'].to(device)\n",
        "      outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "      _, preds = torch.max(outputs, dim =1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "  # return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhHoFNsxufs",
        "outputId": "6b13c18a-0836-4230-9d15-6361a199b93d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  # TODO: Q10. Complete the code below to track train and test accuracy.losses\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.4094420922478623 accuracy 0.8460941359113683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.5253862304985524 accuracy 0.8170266836086404\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.23121734824489895 accuracy 0.9269635170418461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.598971108654514 accuracy 0.8449809402795426\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.15400671872899513 accuracy 0.9559664102745044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6778461206750944 accuracy 0.8564167725540026\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.11205691093858541 accuracy 0.9681744407592972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6958705109800212 accuracy 0.8627700127064803\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09827191805210528 accuracy 0.9712088067179452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6958705109800212 accuracy 0.8627700127064803\n",
            "\n",
            "CPU times: user 20min 2s, sys: 13min 40s, total: 33min 43s\n",
            "Wall time: 33min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the best model, indicated by the highest validation accuracy.\n",
        "\n",
        "Plot train and validation accuracy as a function of epoch count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWG7kBm372V",
        "outputId": "eaebb1f1-f743-4bc3-9da3-7b0372472f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# TODO: Q11. Plot train/validation accuracies.\n",
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "# plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbf1f75bda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "You might try to fine-tune the parameters (learning rate, batch size) a bit more if accuracy is not good enough.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgR6MuNS8jr_"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdPZr60-0c_",
        "outputId": "9794ee78-4045-48cd-b203-3009180dce0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Let us compare true sentiment vs predicted sentiment by plotting a confusion matrix of `y_test` vs `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1qxsc__DTh",
        "outputId": "2934e6bb-ed71-46bb-f563-ae1c4602c73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "# TODO. Q12. Plot the 3x3 confusion matrix and show that the model finds it a bit difficult to classify neutral reviews.\n",
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "source": [
        "review_text = \"I love Deep Learning! Best course evah!!!1!!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Use your trained model to predict the sentiment expressed in `review_text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_t3rUksumr",
        "outputId": "5fb7ef3c-ec1b-432d-a0c1-a00e8647ec0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q13. Print the predicted sentiment in `review_text`.\n",
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1FrTIZi1oZw",
        "outputId": "4e765782-bf7e-4ce7-d328-bdbade40c4e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "output = model(input_ids, attention_mask)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review text: I love Deep Learning! Best course evah!!!1!!\n",
            "Sentiment  : positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}